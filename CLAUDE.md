# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Commands

### Running the Application
```bash
# Start the Streamlit development server
uv run streamlit run src/media_analyst/ui/app.py

# The app will be available at http://localhost:8501
```

### Dependency Management
```bash
# Add a new dependency
uv add <package>

# Sync dependencies from uv.lock
uv sync
```

## Architecture

This is a **Streamlit-based web UI wrapper** around the [MediaCrawler](https://github.com/NanmiCoder/MediaCrawler) project.

### Core Design Principles

#### 1. Functional Core, Imperative Shell (FCIS)

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†ä¸šåŠ¡é€»è¾‘ï¼ˆçº¯å‡½æ•°ï¼‰ä¸å‰¯ä½œç”¨ï¼ˆIOã€çŠ¶æ€å˜æ›´ï¼‰ä¸¥æ ¼åˆ†ç¦»ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        UI Layer                              â”‚
â”‚  (Streamlit - ç”¨æˆ·äº¤äº’ã€çŠ¶æ€ç®¡ç†)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ build_request()
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Functional Core                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Models    â”‚  â”‚    Params    â”‚  â”‚      Config      â”‚  â”‚
â”‚  â”‚  (Pydantic)  â”‚  â”‚ (Pure Funcs) â”‚  â”‚    (Constants)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  ç‰¹ç‚¹ï¼šæ— å‰¯ä½œç”¨ã€å¯æµ‹è¯•ã€å¯åºåˆ—åŒ–ã€ç±»å‹å®‰å…¨                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ CrawlerRunner
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Imperative Shell                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   CrawlerRunner                       â”‚  â”‚
â”‚  â”‚  - subprocess.Popen()  - æ–‡ä»¶ç³»ç»Ÿæ“ä½œ                  â”‚  â”‚
â”‚  â”‚  - å®æ—¶è¾“å‡ºæ•è·        - è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  ç‰¹ç‚¹ï¼šå°è£…æ‰€æœ‰å‰¯ä½œç”¨ã€ä¾¿äºMockã€å¯æ›¿æ¢ä¸ºå…¶ä»–åç«¯              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**FCIS åœ¨æœ¬é¡¹ç›®ä¸­çš„å®è·µ**ï¼š

| å±‚çº§ | èŒè´£ | ç¤ºä¾‹ |
|------|------|------|
| **Core** | æ•°æ®è½¬æ¢ã€éªŒè¯ã€ä¸šåŠ¡è§„åˆ™ | `request.to_cli_args()` çº¯å‡½æ•° |
| **Shell** | IOæ“ä½œã€è¿›ç¨‹ç®¡ç† | `CrawlerRunner.start()` æœ‰å‰¯ä½œç”¨ |
| **UI** | ç”¨æˆ·äº¤äº’ã€è°ƒç”¨Core/Shell | `build_request()` + `runner.start()` |

**FCIS å¸¦æ¥çš„å¥½å¤„**ï¼š
1. **å¯æµ‹è¯•æ€§**ï¼šCore å±‚æ— éœ€ Mockï¼Œç›´æ¥æµ‹è¯•çº¯å‡½æ•°
2. **å¯ç»´æŠ¤æ€§**ï¼šä¸šåŠ¡é€»è¾‘ä¸IOåˆ†ç¦»ï¼Œä¿®æ”¹ä¸€è¾¹ä¸å½±å“å¦ä¸€è¾¹
3. **å¯ç§»æ¤æ€§**ï¼šShell å¯æ›¿æ¢ä¸ºè¿œç¨‹æ‰§è¡Œï¼ˆDocker/SSH/K8sï¼‰

#### 2. Make Illegal States Unrepresentable (MISM)

**æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨ç±»å‹ç³»ç»Ÿè®©ä¸åˆæ³•çš„çŠ¶æ€åœ¨ç¼–è¯‘æœŸï¼ˆæˆ–æ¨¡å‹åˆ›å»ºæœŸï¼‰å°±æ— æ³•è¡¨ç¤ºï¼Œè€Œéè¿è¡Œæ—¶æ£€æŸ¥ã€‚

**å®è·µç¤ºä¾‹**ï¼š

```python
# âŒ ä¸æ¨èï¼šé€šç”¨æ¨¡å‹ + è¿è¡Œæ—¶éªŒè¯
class CrawlerRequest(BaseModel):
    crawler_type: str  # "search" | "detail" | "creator"
    keywords: Optional[str] = None
    specified_ids: Optional[str] = None
    creator_ids: Optional[str] = None

# éœ€è¦åœ¨è¿è¡Œæ—¶æ£€æŸ¥
if crawler_type == "search" and not keywords:
    raise ValueError("æœç´¢æ¨¡å¼éœ€è¦å…³é”®è¯")

# âœ… æ¨èï¼šç‰¹å®šæ¨¡å‹ï¼Œè®©ä¸åˆæ³•çŠ¶æ€æ— æ³•è¡¨ç¤º
class SearchRequest(BaseModel):
    crawler_type: Literal["search"] = "search"
    keywords: str  # å¿…å¡«ï¼ŒéOptional

class DetailRequest(BaseModel):
    crawler_type: Literal["detail"] = "detail"
    specified_ids: str  # å¿…å¡«

class CreatorRequest(BaseModel):
    crawler_type: Literal["creator"] = "creator"
    creator_ids: str  # å¿…å¡«
```

**MISM åœ¨æœ¬é¡¹ç›®ä¸­çš„å®è·µ**ï¼š

1. **è¯·æ±‚æ¨¡å‹åˆ†ç¦»**ï¼š
   - `SearchRequest` å¿…é¡»æä¾› `keywords`
   - `DetailRequest` å¿…é¡»æä¾› `specified_ids`
   - `CreatorRequest` å¿…é¡»æä¾› `creator_ids`

2. **æ‰§è¡ŒçŠ¶æ€éªŒè¯**ï¼š
   ```python
   class CrawlerExecution(BaseModel):
       @model_validator(mode="after")
       def validate_status_consistency(self):
           # RUNNING çŠ¶æ€å¿…é¡»æœ‰ process_id
           if self.status == ExecutionStatus.RUNNING and self.process_id is None:
               raise ValueError("running çŠ¶æ€å¿…é¡»æœ‰ process_id")
           # COMPLETED çŠ¶æ€å¿…é¡»æœ‰ end_time
           if self.status == ExecutionStatus.COMPLETED and self.end_time is None:
               raise ValueError("completed çŠ¶æ€å¿…é¡»æœ‰ end_time")
   ```

3. **è¾“å‡ºæ–‡ä»¶å­˜åœ¨æ€§éªŒè¯**ï¼š
   ```python
   @model_validator(mode="after")
   def validate_output_files_exist(self):
       for file_path in self.output_files:
           if not file_path.exists():
               raise ValueError(f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
   ```

### Key Components

**src/media_analyst/core/** - Functional Core (pure functions, no side effects)
- `models.py` - Pydantic data models (SearchRequest, DetailRequest, CreatorRequest, CrawlerExecution)
- `params.py` - Pure functions for building CLI arguments
- `config.py` - Constants and mappings
- `url_parser.py` - Douyin URL extraction and normalization (pure functions)

**src/media_analyst/shell/** - Imperative Shell (side effects)
- `runner.py` - CrawlerRunner class for process management (subprocess)

**src/media_analyst/ui/** - Streamlit UI
- `app.py` - Main application with form builders and execution logic

### Data Flow

```
ç”¨æˆ·è¾“å…¥ â†’ build_request() â†’ Pydantic Model â†’ to_cli_args() â†’ CLI Args
                                                            â†“
UI æ˜¾ç¤º â† CrawlerExecution â† CrawlerRunner â† subprocess.Popen
```

1. User configures options via Streamlit sidebar and main form
2. `build_request()` creates a Pydantic model (SearchRequest/DetailRequest/CreatorRequest)
3. `request.to_cli_args()` generates CLI arguments (pure function)
4. `CrawlerRunner.start(request)` spawns subprocess: `uv run main.py [args]`
5. `CrawlerExecution` tracks process state, stdout/stderr, and output files

### URL Parsing (Douyin)

The application includes a URL parser for Douyin links that supports extracting and normalizing various URL formats:

**Supported URL formats:**
- Short links: `https://v.douyin.com/xxxxx/` (requires resolver for full normalization)
- Video pages: `https://www.douyin.com/video/xxxxx`
- Note pages: `https://www.douyin.com/note/xxxxx` â†’ normalized to video format
- Featured pages: `https://www.douyin.com/jingxuan?modal_id=xxxxx` â†’ normalized to video format
- Mobile pages: `https://m.douyin.com/share/video/xxxxx` â†’ normalized to video format

**Usage in Core:**
```python
from media_analyst.core import extract_douyin_links, format_link_for_display

# Extract links from share text or comma-separated URLs
text = "6.61 w@f.bn https://v.douyin.com/abc123/ å¤åˆ¶æ­¤é“¾æ¥"
links = extract_douyin_links(text)

# links[0].link_type == "short"
# links[0].video_id == "abc123"
# links[0].normalized == "https://v.douyin.com/abc123/" (unchanged for short links)

# To resolve short links, provide a resolver function:
def resolve_short_link(url: str) -> str:
    import requests
    response = requests.head(url, allow_redirects=True)
    return response.url

links = extract_douyin_links(text, short_link_resolver=resolve_short_link)
# Now links[0].link_type == "video" with real video ID
```

**Note:** Short link resolution requires HTTP requests (side effects), so it's implemented as an optional callback. The Core layer remains pure - the Shell layer can provide the resolver when needed.

### External Dependency

The application **requires MediaCrawler to be installed separately** at a hardcoded path:
```python
MEDIA_CRAWLER_PATH = Path("../MediaCrawler")
```

This path is used as the working directory when spawning the crawler subprocess. If MediaCrawler is not present at this location, the application will fail at runtime.

### Supported Platforms

The UI supports configuring crawlers for: å°çº¢ä¹¦ (xhs), æŠ–éŸ³ (dy), å¿«æ‰‹ (ks), Bç«™ (bili), å¾®åš (wb), è´´å§ (tieba), çŸ¥ä¹ (zhihu)

## Testing

é¡¹ç›®é‡‡ç”¨åˆ†å±‚æµ‹è¯•æ¶æ„ï¼Œ**ä¸¥æ ¼å¯¹åº” FCIS æ¶æ„åˆ†å±‚**ï¼š

```
tests/
â”œâ”€â”€ unit/              # æµ‹è¯• Core å±‚ï¼ˆçº¯å‡½æ•°ï¼Œæ— éœ€ Mockï¼‰
â”œâ”€â”€ integration/       # æµ‹è¯• Shell å±‚ï¼ˆMock å‰¯ä½œç”¨ï¼‰
â”œâ”€â”€ ui/                # æµ‹è¯• UI å±‚ï¼ˆAppTestï¼ŒéªŒè¯æ¨¡å‹è¾“å‡ºï¼‰
â””â”€â”€ real_crawler/      # ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆçœŸå®è¿›ç¨‹ï¼Œæ…¢é€Ÿï¼‰
```

### 1. å•å…ƒæµ‹è¯• (`tests/unit/`)

**æµ‹è¯•ç›®æ ‡**ï¼šCore å±‚çš„çº¯å‡½æ•°å’Œæ¨¡å‹éªŒè¯

**ç‰¹ç‚¹**ï¼š
- âš¡ **æé€Ÿ**ï¼šæ— éœ€ MediaCrawlerï¼Œæ— éœ€æ–‡ä»¶ç³»ç»Ÿ
- ğŸ¯ **ç²¾å‡†**ï¼šå¤±è´¥å³è¯´æ˜ä¸šåŠ¡é€»è¾‘æœ‰é—®é¢˜
- ğŸ“¦ **ç‹¬ç«‹**ï¼šæ¯ä¸ªæµ‹è¯•ä¸ä¾èµ–å¤–éƒ¨çŠ¶æ€

```bash
# è¿è¡Œå•å…ƒæµ‹è¯•ï¼ˆ40ä¸ªï¼Œ<1ç§’ï¼‰
uv run pytest tests/unit -v
```

æµ‹è¯•è¦†ç›–ï¼š
- Pydantic æ¨¡å‹éªŒè¯ï¼ˆMISM åŸåˆ™ï¼‰
- `build_args()` çº¯å‡½æ•°
- `to_cli_args()` æ–¹æ³•
- æ¨¡å‹åºåˆ—åŒ–/ååºåˆ—åŒ–
- URL è§£æï¼ˆ`extract_douyin_links`, `parse_douyin_url`ï¼‰- æ”¯æŒå¤šç§æŠ–éŸ³é“¾æ¥æ ¼å¼

**ç¤ºä¾‹**ï¼ˆçº¯å‡½æ•°æµ‹è¯•ï¼‰ï¼š
```python
def test_build_args_is_pure():
    """ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡ºï¼Œä¸ä¿®æ”¹åŸå¯¹è±¡"""
    req = SearchRequest(platform=Platform.DY, keywords="æµ‹è¯•")
    args1 = build_args(req)
    args2 = build_args(req)
    assert args1 == args2  # å¹‚ç­‰
    assert req.keywords == "æµ‹è¯•"  # æœªä¿®æ”¹åŸå¯¹è±¡
```

### 2. é›†æˆæµ‹è¯• (`tests/integration/`)

**æµ‹è¯•ç›®æ ‡**ï¼šShell å±‚çš„ Runnerï¼Œä½¿ç”¨ mock subprocess

**ç‰¹ç‚¹**ï¼š
- ğŸ­ Mock å¤–éƒ¨ä¾èµ–ï¼ˆsubprocessï¼‰
- ğŸ” éªŒè¯ Runner ä¸ Core çš„é›†æˆ
- âš¡ å¿«é€Ÿæ‰§è¡Œï¼ˆæ— éœ€çœŸå®çˆ¬è™«ï¼‰

```bash
# è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆ14ä¸ªï¼‰
uv run pytest tests/integration -v
```

### 3. UI æµ‹è¯• (`tests/ui/`)

**æµ‹è¯•ç›®æ ‡**ï¼šStreamlit ç•Œé¢å’Œ `build_request()` è¾“å‡º

**ç‰¹ç‚¹**ï¼š
- ğŸ–¥ï¸ ä½¿ç”¨ `streamlit.testing.v1.AppTest`
- âœ… éªŒè¯ UI æ“ä½œè¾“å‡ºæ­£ç¡®çš„ Pydantic æ¨¡å‹
- ğŸ”— è¿æ¥ç”¨æˆ·æ“ä½œä¸ Core å±‚

```bash
# è¿è¡ŒUIæµ‹è¯•ï¼ˆ13ä¸ªï¼‰
uv run pytest tests/ui -v
```

**å…³é”®æµ‹è¯•**ï¼šéªŒè¯ UI è¾“å‡ºæ­£ç¡®çš„æ¨¡å‹ç±»å‹
```python
def test_build_search_request():
    """UI è¡¨å•åº”è¾“å‡º SearchRequest æ¨¡å‹"""
    request = build_request(common_config, mode_config)
    assert isinstance(request, SearchRequest)
    assert request.keywords == "ç¾é£Ÿ,æ—…æ¸¸"
```

### 4. çœŸå®çˆ¬è™«æµ‹è¯• (`tests/real_crawler/`)

**æµ‹è¯•ç›®æ ‡**ï¼šå®Œæ•´æ•°æ®æµéªŒè¯ï¼ˆéœ€è¦çœŸå® MediaCrawler ç¯å¢ƒï¼‰

**ç‰¹ç‚¹**ï¼š
- ğŸ¢ æ…¢é€Ÿæ‰§è¡Œï¼ˆéœ€è¦æ‰«ç ã€ç½‘ç»œè¯·æ±‚ï¼‰
- âœ… éªŒè¯å®Œæ•´æ•°æ®æµï¼šModel â†’ Runner â†’ Execution
- ğŸ‘¤ å¯èƒ½éœ€è¦äººå·¥ä»‹å…¥ï¼ˆé¦–æ¬¡æ‰«ç ç™»å½•ï¼‰

```bash
# è¿è¡ŒçœŸå®çˆ¬è™«æµ‹è¯•ï¼ˆ4ä¸ªï¼Œæ…¢é€Ÿï¼‰
uv run pytest tests/real_crawler -v -s
```

### æµ‹è¯•é…ç½®
- æµ‹è¯•æ¡†æ¶: `pytest` + `pytest-timeout` + `pytest-asyncio`
- è¶…æ—¶è®¾ç½®: 5åˆ†é’Ÿï¼ˆå…è®¸æ‰«ç å’Œçˆ¬å–ï¼‰
- æµ‹è¯•ç›®å½•: `tests/`
- æ ‡è®°: `real_crawler`ï¼ˆçœŸå®çˆ¬è™«ï¼‰, `human_interaction`ï¼ˆéœ€äººå·¥ä»‹å…¥ï¼‰, `slow`ï¼ˆæ‰§è¡Œæ…¢ï¼‰

### æµ‹è¯•ç¼–å†™è§„èŒƒ

1. **åå¥½å‡½æ•°å½¢å¼**ï¼šä½¿ç”¨ `def test_xxx()` è€Œé `class TestXxx:`
2. **æŒ‰ä¸»é¢˜åˆ†æ–‡ä»¶**ï¼šä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ä¸€ä¸ªä¸»é¢˜ï¼ˆå¦‚ test_core_models.pyï¼‰
3. **ä½¿ç”¨æ³¨é‡Šåˆ†ç»„**ï¼šç”¨ `===` åˆ†éš”ä¸åŒä¸»é¢˜çš„æµ‹è¯•
4. **å‘½åæ¸…æ™°**ï¼š`test_<è¢«æµ‹å¯¹è±¡>_<åœºæ™¯>_<é¢„æœŸç»“æœ>`

## Development Notes

- Python version: 3.14+ (specified in `.python-version`)
- Package manager: `uv` with Tsinghua PyPI mirror configured
- Project layout: `src/` layout (modern Python packaging)
- Architecture: Functional Core, Imperative Shell (FCIS)
- Design Principle: Make Illegal States Unrepresentable (MISM)
- The TODO.md tracks known issues: logging cleanup, button states, speed optimization, and UI state persistence

## Key Insights

### 1. FCIS æ¶æ„çš„ä»·å€¼

**é‡æ„å‰**ï¼š
```python
# streamlit_app.py - æ··åˆé€»è¾‘å’ŒIO
def run_crawler(args):
    process = subprocess.Popen(...)  # IO æ··åˆåœ¨ä¸šåŠ¡é€»è¾‘ä¸­
    while True:
        line = process.stdout.readline()
        # å¤„ç†è¾“å‡º...
```

**é‡æ„å**ï¼š
```python
# core/params.py - çº¯å‡½æ•°
def build_args(request: CrawlerRequest) -> list[str]:
    return request.to_cli_args()  # æ— å‰¯ä½œç”¨ï¼Œæ˜“æµ‹è¯•

# shell/runner.py - å°è£…IO
class CrawlerRunner:
    def start(self, request: CrawlerRequest) -> CrawlerExecution:
        # IO æ“ä½œå°è£…åœ¨è¿™é‡Œ
```

### 2. Pydantic æ¨¡å‹ä½œä¸ºé˜²è…å±‚

Pydantic æ¨¡å‹åœ¨ä»£ç ä¸­å……å½“**æ•°æ®å¥‘çº¦**ï¼š
- UI å±‚è¾“å‡º `CrawlerRequest`
- Core å±‚å¤„ç† `CrawlerRequest`
- Shell å±‚æ¥æ”¶ `CrawlerRequest`ï¼Œè¾“å‡º `CrawlerExecution`

å„å±‚ä¹‹é—´é€šè¿‡å¼ºç±»å‹æ¨¡å‹äº¤äº’ï¼Œé¿å…éšå¼å­—å…¸ä¼ é€’ã€‚

### 3. æµ‹è¯•å³æ¶æ„éªŒè¯

æµ‹è¯•ç»“æ„ç›´æ¥åæ˜ æ¶æ„åˆ†å±‚ï¼š
- `tests/unit/` â†’ Core å±‚ï¼ˆçº¯å‡½æ•°ï¼‰
- `tests/integration/` â†’ Shell å±‚ï¼ˆå‰¯ä½œç”¨ï¼‰
- `tests/ui/` â†’ UI å±‚ï¼ˆäº¤äº’ï¼‰

å¦‚æœæµ‹è¯•éš¾ä»¥ç¼–å†™ï¼Œè¯´æ˜æ¶æ„å¯èƒ½éœ€è¦è°ƒæ•´ã€‚
