# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Commands

### Running the Application
```bash
# Start the Streamlit development server
uv run streamlit run src/media_analyst/ui/app.py

# The app will be available at http://localhost:8501
```

### Dependency Management
```bash
# Add a new dependency
uv add <package>

# Sync dependencies from uv.lock
uv sync
```

### Linting & Formatting

é¡¹ç›®ä½¿ç”¨ **Ruff** è¿›è¡Œä»£ç  linting å’Œæ ¼å¼åŒ–ï¼ˆæ›¿ä»£ black + isort + flake8ï¼‰ï¼š

```bash
# æ£€æŸ¥ä»£ç ï¼ˆä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œè‡ªåŠ¨æ’é™¤ .venv/ ç­‰ç›®å½•ï¼‰
uv run ruff check .

# è‡ªåŠ¨ä¿®å¤å¯ä¿®å¤çš„é—®é¢˜
uv run ruff check . --fix

# æ ¼å¼åŒ–ä»£ç 
uv run ruff format .

# æ£€æŸ¥æ ¼å¼åŒ–ï¼ˆä¸ä¿®æ”¹æ–‡ä»¶ï¼‰
uv run ruff format --check .
```

**Ruff é…ç½®**ï¼ˆ`pyproject.toml`ï¼‰ï¼š
- è¡Œé•¿åº¦: 120 å­—ç¬¦
- Python ç›®æ ‡ç‰ˆæœ¬: 3.13
- å¼•å·é£æ ¼: å•å¼•å·
- å¯ç”¨è§„åˆ™: `E` (pycodestyle), `F` (Pyflakes), `I` (isort)

### Git Hooks (Prek)

é¡¹ç›®ä½¿ç”¨ **prek** ä½œä¸º Git pre-commit hookï¼Œåœ¨æäº¤å‰è‡ªåŠ¨è¿è¡Œä»£ç æ£€æŸ¥å’Œæµ‹è¯•ï¼š

```bash
# å®‰è£… prekï¼ˆé¦–æ¬¡ï¼‰
uv tool install prek

# å®‰è£… git hooksï¼ˆé¡¹ç›®åˆå§‹åŒ–æ—¶ï¼‰
prek install

# æŸ¥çœ‹å·²é…ç½®çš„ hooks
prek list

# æ‰‹åŠ¨è¿è¡Œæ‰€æœ‰ hooks
prek run --all-files

# ä»…è¿è¡Œç‰¹å®š hook
prek run ruff --all-files

# è·³è¿‡ hooksï¼ˆç´§æ€¥æƒ…å†µï¼‰
git commit --no-verify -m "hotfix"
```

**prek é…ç½®**ï¼ˆ`.pre-commit-config.yaml`ï¼‰ï¼š
- **Ruff Linter**: è‡ªåŠ¨ä¿®å¤ä»£ç é—®é¢˜
- **Ruff Formatter**: æ ¼å¼åŒ–ä»£ç 
- **Pytest**: è¿è¡Œå•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•å’Œ UI æµ‹è¯•

**ä¸ºä»€ä¹ˆä½¿ç”¨ prekï¼Ÿ**
- prek æ˜¯ç”¨ Rust é‡å†™çš„ pre-commitï¼Œå®Œå…¨å…¼å®¹å…¶é…ç½®æ ¼å¼
- é€Ÿåº¦æ›´å¿«ï¼Œå•äºŒè¿›åˆ¶æ–‡ä»¶æ— é¢å¤–ä¾èµ–
- åŸç”Ÿæ”¯æŒå¹¶è¡Œæ‰§è¡Œå’Œ uv é›†æˆ

> **æ³¨æ„**: prek ä¸æ˜¯ Python ä¾èµ–ï¼Œéœ€è¦é€šè¿‡ `uv tool install` å•ç‹¬å®‰è£…ã€‚

## Architecture

This is a **Streamlit-based web UI wrapper** around the [MediaCrawler](https://github.com/NanmiCoder/MediaCrawler) project.

### Core Design Principles

#### 1. Functional Core, Imperative Shell (FCIS)

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†ä¸šåŠ¡é€»è¾‘ï¼ˆçº¯å‡½æ•°ï¼‰ä¸å‰¯ä½œç”¨ï¼ˆIOã€çŠ¶æ€å˜æ›´ï¼‰ä¸¥æ ¼åˆ†ç¦»ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        UI Layer                              â”‚
â”‚  (Streamlit - ç”¨æˆ·äº¤äº’ã€çŠ¶æ€ç®¡ç†)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ build_request()
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Functional Core                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Models    â”‚  â”‚    Params    â”‚  â”‚      Config      â”‚  â”‚
â”‚  â”‚  (Pydantic)  â”‚  â”‚ (Pure Funcs) â”‚  â”‚    (Constants)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  ç‰¹ç‚¹ï¼šæ— å‰¯ä½œç”¨ã€å¯æµ‹è¯•ã€å¯åºåˆ—åŒ–ã€ç±»å‹å®‰å…¨                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ CrawlerRunner
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Imperative Shell                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   CrawlerRunner                       â”‚  â”‚
â”‚  â”‚  - subprocess.Popen()  - æ–‡ä»¶ç³»ç»Ÿæ“ä½œ                  â”‚  â”‚
â”‚  â”‚  - å®æ—¶è¾“å‡ºæ•è·        - è¿›ç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  ç‰¹ç‚¹ï¼šå°è£…æ‰€æœ‰å‰¯ä½œç”¨ã€ä¾¿äºMockã€å¯æ›¿æ¢ä¸ºå…¶ä»–åç«¯              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**FCIS åœ¨æœ¬é¡¹ç›®ä¸­çš„å®è·µ**ï¼š

| å±‚çº§ | èŒè´£ | ç¤ºä¾‹ |
|------|------|------|
| **Core** | æ•°æ®è½¬æ¢ã€éªŒè¯ã€ä¸šåŠ¡è§„åˆ™ | `request.to_cli_args()` çº¯å‡½æ•° |
| **Shell** | IOæ“ä½œã€è¿›ç¨‹ç®¡ç† | `CrawlerRunner.start()` æœ‰å‰¯ä½œç”¨ |
| **UI** | ç”¨æˆ·äº¤äº’ã€è°ƒç”¨Core/Shell | `build_request()` + `runner.start()` |

**FCIS å¸¦æ¥çš„å¥½å¤„**ï¼š
1. **å¯æµ‹è¯•æ€§**ï¼šCore å±‚æ— éœ€ Mockï¼Œç›´æ¥æµ‹è¯•çº¯å‡½æ•°
2. **å¯ç»´æŠ¤æ€§**ï¼šä¸šåŠ¡é€»è¾‘ä¸IOåˆ†ç¦»ï¼Œä¿®æ”¹ä¸€è¾¹ä¸å½±å“å¦ä¸€è¾¹
3. **å¯ç§»æ¤æ€§**ï¼šShell å¯æ›¿æ¢ä¸ºè¿œç¨‹æ‰§è¡Œï¼ˆDocker/SSH/K8sï¼‰

#### 2. Make Illegal States Unrepresentable (MISM)

**æ ¸å¿ƒæ€æƒ³**ï¼šåˆ©ç”¨ç±»å‹ç³»ç»Ÿè®©ä¸åˆæ³•çš„çŠ¶æ€åœ¨ç¼–è¯‘æœŸï¼ˆæˆ–æ¨¡å‹åˆ›å»ºæœŸï¼‰å°±æ— æ³•è¡¨ç¤ºï¼Œè€Œéè¿è¡Œæ—¶æ£€æŸ¥ã€‚

**å®è·µç¤ºä¾‹**ï¼š

```python
# âŒ ä¸æ¨èï¼šé€šç”¨æ¨¡å‹ + è¿è¡Œæ—¶éªŒè¯
class CrawlerRequest(BaseModel):
    crawler_type: str  # "search" | "detail" | "creator"
    keywords: Optional[str] = None
    specified_ids: Optional[str] = None
    creator_ids: Optional[str] = None

# éœ€è¦åœ¨è¿è¡Œæ—¶æ£€æŸ¥
if crawler_type == "search" and not keywords:
    raise ValueError("æœç´¢æ¨¡å¼éœ€è¦å…³é”®è¯")

# âœ… æ¨èï¼šç‰¹å®šæ¨¡å‹ï¼Œè®©ä¸åˆæ³•çŠ¶æ€æ— æ³•è¡¨ç¤º
class SearchRequest(BaseModel):
    crawler_type: Literal["search"] = "search"
    keywords: str  # å¿…å¡«ï¼ŒéOptional

class DetailRequest(BaseModel):
    crawler_type: Literal["detail"] = "detail"
    specified_ids: str  # å¿…å¡«

class CreatorRequest(BaseModel):
    crawler_type: Literal["creator"] = "creator"
    creator_ids: str  # å¿…å¡«
```

**MISM åœ¨æœ¬é¡¹ç›®ä¸­çš„å®è·µ**ï¼š

1. **è¯·æ±‚æ¨¡å‹åˆ†ç¦»**ï¼š
   - `SearchRequest` å¿…é¡»æä¾› `keywords`
   - `DetailRequest` å¿…é¡»æä¾› `specified_ids`
   - `CreatorRequest` å¿…é¡»æä¾› `creator_ids`

2. **æ‰§è¡ŒçŠ¶æ€éªŒè¯**ï¼š
   ```python
   class CrawlerExecution(BaseModel):
       @model_validator(mode="after")
       def validate_status_consistency(self):
           # RUNNING çŠ¶æ€å¿…é¡»æœ‰ process_id
           if self.status == ExecutionStatus.RUNNING and self.process_id is None:
               raise ValueError("running çŠ¶æ€å¿…é¡»æœ‰ process_id")
           # COMPLETED çŠ¶æ€å¿…é¡»æœ‰ end_time
           if self.status == ExecutionStatus.COMPLETED and self.end_time is None:
               raise ValueError("completed çŠ¶æ€å¿…é¡»æœ‰ end_time")
   ```

3. **è¾“å‡ºæ–‡ä»¶å­˜åœ¨æ€§éªŒè¯**ï¼š
   ```python
   @model_validator(mode="after")
   def validate_output_files_exist(self):
       for file_path in self.output_files:
           if not file_path.exists():
               raise ValueError(f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
   ```

### Key Components

**src/media_analyst/core/** - Functional Core (pure functions, no side effects)
- `models.py` - Pydantic data models
  - Crawler: `SearchRequest`, `DetailRequest`, `CreatorRequest`, `CrawlerExecution`
  - Parser: `Post`, `Comment`, `ParsedData` (è§£æç»“æœæ¨¡å‹)
- `params.py` - Pure functions for building CLI arguments
- `config.py` - Constants and mappings
- `url_parser.py` - Douyin URL extraction and normalization (pure functions)
- `parser.py` - Data parser (è‡ªåŠ¨æ£€æµ‹å¹³å°ã€å»é‡å¤„ç†)

**src/media_analyst/shell/** - Imperative Shell (side effects)
- `runner.py` - CrawlerRunner class for process management (subprocess)

**src/media_analyst/ui/** - Streamlit UI
- `app.py` - Main application with form builders and execution logic
- `parser_page.py` - Data parser page (è¯»å–-è§£æ-é¢„è§ˆ)
- `persistence.py` - User preferences and path management (ç»Ÿä¸€ç®¡ç† MediaCrawler è·¯å¾„)

### Data Flow

```
ç”¨æˆ·è¾“å…¥ â†’ build_request() â†’ Pydantic Model â†’ to_cli_args() â†’ CLI Args
                                                            â†“
UI æ˜¾ç¤º â† CrawlerExecution â† CrawlerRunner â† subprocess.Popen
```

1. User configures options via Streamlit sidebar and main form
2. `build_request()` creates a Pydantic model (SearchRequest/DetailRequest/CreatorRequest)
3. `request.to_cli_args()` generates CLI arguments (pure function)
4. `CrawlerRunner.start(request)` spawns subprocess: `uv run main.py [args]`
5. `CrawlerExecution` tracks process state, stdout/stderr, and output files

### Data Parsing

The application includes a separate data parsing page (`parser_page.py`) for parsing crawled JSON data:

**Features:**
- Accept directory input (recursively finds all `.json` files)
- Auto-detect platform from filename and content
- Deduplication (keeps latest crawl based on filename timestamp)
- Preview parsed data in tables

**Deduplication Strategy:**
```python
# Post: (platform, content_id) as unique key
# Comment: (platform, comment_id) as unique key
# Keep the one with latest crawl_time
```

**Crawl Time Extraction:**
- Extracted from filename: `douyin_contents_2024_0221_143052.json` â†’ `2024-02-21 14:30:52`
- Fallback to file modification time

### URL Parsing (Douyin)

The application includes a URL parser for Douyin links that supports extracting and normalizing various URL formats:

**Supported URL formats:**
- Short links: `https://v.douyin.com/xxxxx/` (requires resolver for full normalization)
- Video pages: `https://www.douyin.com/video/xxxxx`
- Note pages: `https://www.douyin.com/note/xxxxx` â†’ normalized to video format
- Featured pages: `https://www.douyin.com/jingxuan?modal_id=xxxxx` â†’ normalized to video format
- Mobile pages: `https://m.douyin.com/share/video/xxxxx` â†’ normalized to video format

**Usage in Core:**
```python
from media_analyst.core import extract_douyin_links, format_link_for_display

# Extract links from share text or comma-separated URLs
text = "6.61 w@f.bn https://v.douyin.com/abc123/ å¤åˆ¶æ­¤é“¾æ¥"
links = extract_douyin_links(text)

# links[0].link_type == "short"
# links[0].video_id == "abc123"
# links[0].normalized == "https://v.douyin.com/abc123/" (unchanged for short links)

# To resolve short links, provide a resolver function:
def resolve_short_link(url: str) -> str:
    import requests
    response = requests.head(url, allow_redirects=True)
    return response.url

links = extract_douyin_links(text, short_link_resolver=resolve_short_link)
# Now links[0].link_type == "video" with real video ID
```

**Note:** Short link resolution requires HTTP requests (side effects), so it's implemented as an optional callback. The Core layer remains pure - the Shell layer can provide the resolver when needed.

### External Dependency

### MediaCrawler Path Configuration

The application uses a **unified path management** system via `persistence.py`:

**Path Resolution Priority:**
1. User saved path (stored in `~/.media_analyst/preferences.json`)
2. Auto-detected path (multiple strategies)
3. Default: `../MediaCrawler` (relative to working directory)

**Auto-detection Strategies:**
- Current working directory relative (`../MediaCrawler`)
- Based on `__file__` location
- CWD parents traversal
- Common absolute paths (`~/MediaCrawler`, `~/projects/MediaCrawler`)

**Usage:**
```python
from media_analyst.ui.persistence import get_media_crawler_path

# Get path (auto-resolves using priority above)
mc_path = get_media_crawler_path()

# Save custom path
save_media_crawler_path("/path/to/MediaCrawler")
```

Both the crawler page and parser page use this unified configuration.

### Supported Platforms

The UI supports configuring crawlers for: å°çº¢ä¹¦ (xhs), æŠ–éŸ³ (dy), å¿«æ‰‹ (ks), Bç«™ (bili), å¾®åš (wb), è´´å§ (tieba), çŸ¥ä¹ (zhihu)

## Testing

é¡¹ç›®é‡‡ç”¨åˆ†å±‚æµ‹è¯•æ¶æ„ï¼Œ**ä¸¥æ ¼å¯¹åº” FCIS æ¶æ„åˆ†å±‚**ï¼š

```
tests/
â”œâ”€â”€ unit/              # æµ‹è¯• Core å±‚ï¼ˆçº¯å‡½æ•°ï¼Œæ— éœ€ Mockï¼‰
â”œâ”€â”€ integration/       # æµ‹è¯• Shell å±‚ï¼ˆMock å‰¯ä½œç”¨ï¼‰
â”œâ”€â”€ ui/                # æµ‹è¯• UI å±‚ï¼ˆAppTestï¼ŒéªŒè¯æ¨¡å‹è¾“å‡ºï¼‰
â””â”€â”€ real_crawler/      # ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆçœŸå®è¿›ç¨‹ï¼Œæ…¢é€Ÿï¼‰
```

### 1. å•å…ƒæµ‹è¯• (`tests/unit/`)

**æµ‹è¯•ç›®æ ‡**ï¼šCore å±‚çš„çº¯å‡½æ•°å’Œæ¨¡å‹éªŒè¯

**ç‰¹ç‚¹**ï¼š
- âš¡ **æé€Ÿ**ï¼šæ— éœ€ MediaCrawlerï¼Œæ— éœ€æ–‡ä»¶ç³»ç»Ÿ
- ğŸ¯ **ç²¾å‡†**ï¼šå¤±è´¥å³è¯´æ˜ä¸šåŠ¡é€»è¾‘æœ‰é—®é¢˜
- ğŸ“¦ **ç‹¬ç«‹**ï¼šæ¯ä¸ªæµ‹è¯•ä¸ä¾èµ–å¤–éƒ¨çŠ¶æ€

```bash
# è¿è¡Œå•å…ƒæµ‹è¯•ï¼ˆ~160ä¸ªï¼Œ<1ç§’ï¼‰
uv run pytest tests/unit -v
```

æµ‹è¯•è¦†ç›–ï¼š
- Pydantic æ¨¡å‹éªŒè¯ï¼ˆMISM åŸåˆ™ï¼‰
- `build_args()` çº¯å‡½æ•°
- `to_cli_args()` æ–¹æ³•
- æ¨¡å‹åºåˆ—åŒ–/ååºåˆ—åŒ–
- URL è§£æï¼ˆ`extract_douyin_links`, `parse_douyin_url`ï¼‰
- æ•°æ®è§£æï¼ˆ`parse_json_file`, `parse_json_files`ï¼‰
- å»é‡é€»è¾‘ï¼ˆ`deduplicate`, `deduplication_stats`ï¼‰
- çœŸå®æ•°æ®æ ¼å¼æµ‹è¯•ï¼ˆä½¿ç”¨ MediaCrawler å®é™…è¾“å‡ºæ ¼å¼ï¼‰
- CLI å…¥å£æµ‹è¯•
- åå¥½æŒä¹…åŒ–æµ‹è¯•

**ç¤ºä¾‹**ï¼ˆçº¯å‡½æ•°æµ‹è¯•ï¼‰ï¼š
```python
def test_build_args_is_pure():
    """ç›¸åŒè¾“å…¥äº§ç”Ÿç›¸åŒè¾“å‡ºï¼Œä¸ä¿®æ”¹åŸå¯¹è±¡"""
    req = SearchRequest(platform=Platform.DY, keywords="æµ‹è¯•")
    args1 = build_args(req)
    args2 = build_args(req)
    assert args1 == args2  # å¹‚ç­‰
    assert req.keywords == "æµ‹è¯•"  # æœªä¿®æ”¹åŸå¯¹è±¡
```

### 2. é›†æˆæµ‹è¯• (`tests/integration/`)

**æµ‹è¯•ç›®æ ‡**ï¼šShell å±‚çš„ Runnerï¼Œä½¿ç”¨ mock subprocess

**ç‰¹ç‚¹**ï¼š
- ğŸ­ Mock å¤–éƒ¨ä¾èµ–ï¼ˆsubprocessï¼‰
- ğŸ” éªŒè¯ Runner ä¸ Core çš„é›†æˆ
- âš¡ å¿«é€Ÿæ‰§è¡Œï¼ˆæ— éœ€çœŸå®çˆ¬è™«ï¼‰

```bash
# è¿è¡Œé›†æˆæµ‹è¯•ï¼ˆ~20ä¸ªï¼‰
uv run pytest tests/integration -v
```

æµ‹è¯•è¦†ç›–ï¼š
- Runner åˆå§‹åŒ–å’ŒéªŒè¯
- è¿›ç¨‹å¯åŠ¨å’Œåœæ­¢
- è¾“å‡ºæ•è·å’Œè¶…æ—¶å¤„ç†
- é”™è¯¯å¤„ç†ï¼ˆFileNotFoundError, PermissionError ç­‰ï¼‰

### 3. UI æµ‹è¯• (`tests/ui/`)

**æµ‹è¯•ç›®æ ‡**ï¼šStreamlit ç•Œé¢å’Œ `build_request()` è¾“å‡º

**ç‰¹ç‚¹**ï¼š
- ğŸ–¥ï¸ ä½¿ç”¨ `streamlit.testing.v1.AppTest`
- âœ… éªŒè¯ UI æ“ä½œè¾“å‡ºæ­£ç¡®çš„ Pydantic æ¨¡å‹
- ğŸ”— è¿æ¥ç”¨æˆ·æ“ä½œä¸ Core å±‚

```bash
# è¿è¡ŒUIæµ‹è¯•ï¼ˆ~80ä¸ªï¼‰
uv run pytest tests/ui -v
```

**æµ‹è¯•è¦†ç›–**ï¼š
- ä¸»åº”ç”¨é¡µé¢åŠ è½½å’Œäº¤äº’
- æ•°æ®è§£æé¡µé¢åŠŸèƒ½
- å„çˆ¬è™«æ¨¡å¼çš„è¡¨å•æ¸²æŸ“
- `build_request()` è¾“å‡ºéªŒè¯
- ä¾§è¾¹æ é…ç½®ç»„ä»¶

**å…³é”®æµ‹è¯•**ï¼šéªŒè¯ UI è¾“å‡ºæ­£ç¡®çš„æ¨¡å‹ç±»å‹
```python
def test_build_search_request():
    """UI è¡¨å•åº”è¾“å‡º SearchRequest æ¨¡å‹"""
    request = build_request(common_config, mode_config)
    assert isinstance(request, SearchRequest)
    assert request.keywords == "ç¾é£Ÿ,æ—…æ¸¸"
```

### 4. çœŸå®çˆ¬è™«æµ‹è¯• (`tests/real_crawler/`)

**æµ‹è¯•ç›®æ ‡**ï¼šå®Œæ•´æ•°æ®æµéªŒè¯ï¼ˆéœ€è¦çœŸå® MediaCrawler ç¯å¢ƒï¼‰

**ç‰¹ç‚¹**ï¼š
- ğŸ¢ æ…¢é€Ÿæ‰§è¡Œï¼ˆéœ€è¦æ‰«ç ã€ç½‘ç»œè¯·æ±‚ï¼‰
- âœ… éªŒè¯å®Œæ•´æ•°æ®æµï¼šModel â†’ Runner â†’ Execution
- ğŸ‘¤ å¯èƒ½éœ€è¦äººå·¥ä»‹å…¥ï¼ˆé¦–æ¬¡æ‰«ç ç™»å½•ï¼‰

```bash
# è¿è¡ŒçœŸå®çˆ¬è™«æµ‹è¯•ï¼ˆ4ä¸ªï¼Œæ…¢é€Ÿï¼‰
uv run pytest tests/real_crawler -v -s
```

### æµ‹è¯•é…ç½®
- æµ‹è¯•æ¡†æ¶: `pytest` + `pytest-timeout` + `pytest-asyncio` + `pytest-cov`
- è¶…æ—¶è®¾ç½®: 5åˆ†é’Ÿï¼ˆå…è®¸æ‰«ç å’Œçˆ¬å–ï¼‰
- æµ‹è¯•ç›®å½•: `tests/`
- æ ‡è®°: `real_crawler`ï¼ˆçœŸå®çˆ¬è™«ï¼‰, `human_interaction`ï¼ˆéœ€äººå·¥ä»‹å…¥ï¼‰, `slow`ï¼ˆæ‰§è¡Œæ…¢ï¼‰

### è¦†ç›–ç‡æµ‹è¯•

**å½“å‰è¦†ç›–ç‡**ï¼ˆ261 ä¸ªæµ‹è¯•ï¼‰ï¼š

| æ¨¡å— | è¦†ç›–ç‡ | è¯´æ˜ |
|------|--------|------|
| `core/models.py` | 94.9% | Pydantic æ¨¡å‹éªŒè¯ |
| `core/params.py` | 100% | çº¯å‡½æ•° CLI å‚æ•°æ„å»º |
| `core/parser.py` | 91.4% | æ•°æ®è§£æå’Œå¹³å°æ£€æµ‹ |
| `core/url_parser.py` | 98.5% | URL æå–å’Œæ ‡å‡†åŒ– |
| `core/config.py` | 100% | é…ç½®å¸¸é‡ |
| `shell/runner.py` | 93.8% | è¿›ç¨‹ç®¡ç† |
| `ui/persistence.py` | 95.1% | åå¥½æŒä¹…åŒ– |
| `ui/app.py` | 57.0% | ä¸»åº”ç”¨ç•Œé¢ |
| `ui/parser_page.py` | 47.3% | æ•°æ®è§£æé¡µé¢ |
| `cli.py` | 100% | CLI å…¥å£ |
| **æ•´ä½“** | **81.3%** | æ€»è®¡ 1414 è¯­å¥ |

ä½¿ç”¨ `pytest-cov` è¿›è¡Œæµ‹è¯•è¦†ç›–ç‡ç»Ÿè®¡ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•å¹¶æ˜¾ç¤ºè¦†ç›–ç‡æŠ¥å‘Š
uv run pytest tests/unit tests/integration tests/ui --cov --cov-report=term

# ç”Ÿæˆ HTML è¦†ç›–ç‡æŠ¥å‘Šï¼ˆè¯¦ç»†åˆ°æ¯ä¸€è¡Œï¼‰
uv run pytest tests/unit tests/integration tests/ui --cov --cov-report=html

# æŸ¥çœ‹ HTML æŠ¥å‘Š
open htmlcov/index.html

# ä»…æŸ¥çœ‹æœªè¦†ç›–çš„ä»£ç è¡Œ
uv run pytest tests/unit tests/integration tests/ui --cov --cov-report=term-missing

# æŒ‡å®šè¦†ç›–ç‡é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼ä¼šå¤±è´¥ï¼‰
uv run pytest tests/unit tests/integration tests/ui --cov --cov-fail-under=80
```

**è¦†ç›–ç‡é…ç½®**ï¼ˆåœ¨ `pyproject.toml` ä¸­ï¼‰ï¼š
- ç»Ÿè®¡èŒƒå›´ï¼š`src/media_analyst/` ç›®å½•ä¸‹çš„æºä»£ç 
- æ’é™¤é¡¹ï¼šæµ‹è¯•æ–‡ä»¶ã€`__pycache__`ã€TYPE_CHECKING ä»£ç å—
- HTML æŠ¥å‘Šè¾“å‡ºåˆ° `htmlcov/` ç›®å½•

### æµ‹è¯•æ–‡ä»¶ç»„ç»‡

```
tests/
â”œâ”€â”€ unit/                      # å•å…ƒæµ‹è¯•ï¼ˆçº¯å‡½æ•°ï¼Œæ— éœ€ Mockï¼‰
â”‚   â”œâ”€â”€ test_core_models.py    # Pydantic æ¨¡å‹æµ‹è¯•ï¼ˆ44ä¸ªï¼‰
â”‚   â”œâ”€â”€ test_params.py         # CLI å‚æ•°æ„å»ºæµ‹è¯•
â”‚   â”œâ”€â”€ test_parser.py         # æ•°æ®è§£ææµ‹è¯•ï¼ˆ53ä¸ªï¼‰
â”‚   â”œâ”€â”€ test_url_parser.py     # URL è§£ææµ‹è¯•
â”‚   â”œâ”€â”€ test_persistence.py    # åå¥½æŒä¹…åŒ–æµ‹è¯•ï¼ˆ29ä¸ªï¼‰
â”‚   â””â”€â”€ test_cli.py            # CLI å…¥å£æµ‹è¯•ï¼ˆ9ä¸ªï¼‰
â”œâ”€â”€ integration/               # é›†æˆæµ‹è¯•ï¼ˆMock å‰¯ä½œç”¨ï¼‰
â”‚   â””â”€â”€ test_runner.py         # CrawlerRunner æµ‹è¯•ï¼ˆ21ä¸ªï¼‰
â”œâ”€â”€ ui/                        # UI æµ‹è¯•ï¼ˆAppTestï¼‰
â”‚   â”œâ”€â”€ test_streamlit.py      # ä¸»åº”ç”¨æµ‹è¯•ï¼ˆ29ä¸ªï¼‰
â”‚   â””â”€â”€ test_parser_page.py    # è§£æé¡µé¢æµ‹è¯•ï¼ˆ19ä¸ªï¼‰
â””â”€â”€ real_crawler/              # ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆæ…¢é€Ÿï¼‰
    â””â”€â”€ test_real_crawler.py
```

### æµ‹è¯•ç¼–å†™è§„èŒƒ

1. **åå¥½å‡½æ•°å½¢å¼**ï¼šä½¿ç”¨ `def test_xxx()` è€Œé `class TestXxx:`
2. **æŒ‰ä¸»é¢˜åˆ†æ–‡ä»¶**ï¼šä¸€ä¸ªæµ‹è¯•æ–‡ä»¶ä¸€ä¸ªä¸»é¢˜ï¼ˆå¦‚ test_core_models.pyï¼‰
3. **ä½¿ç”¨æ³¨é‡Šåˆ†ç»„**ï¼šç”¨ `===` åˆ†éš”ä¸åŒä¸»é¢˜çš„æµ‹è¯•
4. **å‘½åæ¸…æ™°**ï¼š`test_<è¢«æµ‹å¯¹è±¡>_<åœºæ™¯>_<é¢„æœŸç»“æœ>`
5. **åˆ†å±‚æµ‹è¯•**ï¼š
   - Core å±‚æµ‹è¯•ï¼šç›´æ¥è°ƒç”¨çº¯å‡½æ•°ï¼Œæ— éœ€ Mock
   - Shell å±‚æµ‹è¯•ï¼šä½¿ç”¨ `unittest.mock.patch` æ¨¡æ‹Ÿ IO
   - UI å±‚æµ‹è¯•ï¼šä½¿ç”¨ `streamlit.testing.v1.AppTest`

## Development Notes

- Python version: 3.13+ (specified in `.python-version`)
- Package manager: `uv` with Tsinghua PyPI mirror configured
- Project layout: `src/` layout (modern Python packaging)
- Architecture: Functional Core, Imperative Shell (FCIS)
- Design Principle: Make Illegal States Unrepresentable (MISM)
- Multi-page app: `app.py` (crawler) + `parser_page.py` (data parsing)
- Unified path config: `persistence.py` manages MediaCrawler path
- Git hooks: **prek** for pre-commit checks (Ruff + Pytest)
- The TODO.md tracks known issues: logging cleanup, button states, speed optimization, and UI state persistence

## Key Insights

### 1. FCIS æ¶æ„çš„ä»·å€¼

**é‡æ„å‰**ï¼š
```python
# streamlit_app.py - æ··åˆé€»è¾‘å’ŒIO
def run_crawler(args):
    process = subprocess.Popen(...)  # IO æ··åˆåœ¨ä¸šåŠ¡é€»è¾‘ä¸­
    while True:
        line = process.stdout.readline()
        # å¤„ç†è¾“å‡º...
```

**é‡æ„å**ï¼š
```python
# core/params.py - çº¯å‡½æ•°
def build_args(request: CrawlerRequest) -> list[str]:
    return request.to_cli_args()  # æ— å‰¯ä½œç”¨ï¼Œæ˜“æµ‹è¯•

# shell/runner.py - å°è£…IO
class CrawlerRunner:
    def start(self, request: CrawlerRequest) -> CrawlerExecution:
        # IO æ“ä½œå°è£…åœ¨è¿™é‡Œ
```

### 2. Pydantic æ¨¡å‹ä½œä¸ºé˜²è…å±‚

Pydantic æ¨¡å‹åœ¨ä»£ç ä¸­å……å½“**æ•°æ®å¥‘çº¦**ï¼š
- UI å±‚è¾“å‡º `CrawlerRequest`
- Core å±‚å¤„ç† `CrawlerRequest`
- Shell å±‚æ¥æ”¶ `CrawlerRequest`ï¼Œè¾“å‡º `CrawlerExecution`

å„å±‚ä¹‹é—´é€šè¿‡å¼ºç±»å‹æ¨¡å‹äº¤äº’ï¼Œé¿å…éšå¼å­—å…¸ä¼ é€’ã€‚

### 3. æµ‹è¯•è¦†ç›–ç‡æå‡ç­–ç•¥

**æµ‹è¯•ä½œä¸ºè´¨é‡ä¿éšœ**ï¼š
- æ–°å¢åŠŸèƒ½å¿…é¡»é…å¥—æµ‹è¯•
- Bug ä¿®å¤å…ˆå†™é‡ç°æµ‹è¯•ï¼Œå†ä¿®å¤ä»£ç 
- è¦†ç›–ç‡æŠ¥å‘Šä½œä¸º PR å®¡æŸ¥å‚è€ƒ

**åˆ†å±‚è¦†ç›–ç­–ç•¥**ï¼š
- **Core å±‚**ï¼šè¿½æ±‚ 95%+ è¦†ç›–ç‡ï¼ˆçº¯å‡½æ•°æ˜“äºæµ‹è¯•ï¼‰
- **Shell å±‚**ï¼šè¿½æ±‚ 90%+ è¦†ç›–ç‡ï¼ˆMock å‰¯ä½œç”¨ï¼‰
- **UI å±‚**ï¼šè¦†ç›–å…³é”®ç”¨æˆ·æµç¨‹ï¼ˆè¡¨å•æäº¤ã€çŠ¶æ€è½¬æ¢ï¼‰

**éš¾ä»¥æµ‹è¯•çš„ä»£ç æ˜¯è®¾è®¡é—®é¢˜çš„ä¿¡å·**ï¼š
- å¦‚æœæµ‹è¯•éš¾ä»¥ç¼–å†™ï¼Œè¯´æ˜è€¦åˆåº¦è¿‡é«˜
- è€ƒè™‘é‡æ„ä»¥æé«˜å¯æµ‹è¯•æ€§
- éµå¾ª FCIS æ¶æ„åˆ†ç¦»çº¯å‡½æ•°å’Œå‰¯ä½œç”¨

### 4. æµ‹è¯•å³æ¶æ„éªŒè¯

æµ‹è¯•ç»“æ„ç›´æ¥åæ˜ æ¶æ„åˆ†å±‚ï¼š
- `tests/unit/` â†’ Core å±‚ï¼ˆçº¯å‡½æ•°ï¼‰
- `tests/integration/` â†’ Shell å±‚ï¼ˆå‰¯ä½œç”¨ï¼‰
- `tests/ui/` â†’ UI å±‚ï¼ˆäº¤äº’ï¼‰

å¦‚æœæµ‹è¯•éš¾ä»¥ç¼–å†™ï¼Œè¯´æ˜æ¶æ„å¯èƒ½éœ€è¦è°ƒæ•´ã€‚
