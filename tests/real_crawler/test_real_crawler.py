"""
çœŸå®æ‰§è¡Œ MediaCrawler çš„ E2E æµ‹è¯•

ä½¿ç”¨ Pydantic æ¨¡å‹è¿›è¡Œå®Œæ•´æµ‹è¯•ï¼š
1. æ„å»º CrawlerRequest æ¨¡å‹
2. ä½¿ç”¨ CrawlerRunner æ‰§è¡Œ
3. éªŒè¯ CrawlerExecution ç»“æœ

éœ€è¦ï¼š
- MediaCrawler å·²å®‰è£…åœ¨æ­£ç¡®è·¯å¾„
- äººç±»ä»‹å…¥æ‰«ç ç™»å½•ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
- ç½‘ç»œè¿æ¥æ­£å¸¸

è¿è¡Œå‘½ä»¤:
    uv run pytest tests/e2e/test_real_crawler.py -v -s

å‚æ•°è¯´æ˜:
    -v: è¯¦ç»†è¾“å‡º
    -s: æ˜¾ç¤º stdoutï¼ˆè®©ç”¨æˆ·çœ‹åˆ°äºŒç»´ç å’Œçˆ¬å–æ—¥å¿—ï¼‰
    -m 'real_crawler': åªè¿è¡ŒçœŸå®çˆ¬è™«æµ‹è¯•
"""

import json
import time
from pathlib import Path

import pytest

from media_analyst.core.models import (
    CrawlerExecution,
    DetailRequest,
    ExecutionStatus,
    LoginType,
    Platform,
    SearchRequest,
)
from media_analyst.core.params import build_command
from media_analyst.shell import CrawlerRunner

# è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰- 5åˆ†é’Ÿï¼Œå…è®¸æ‰«ç å’Œçˆ¬å–
TEST_TIMEOUT = 300


@pytest.fixture
def media_crawler_path() -> Path:
    """è¿”å› MediaCrawler é¡¹ç›®è·¯å¾„"""
    return Path("../MediaCrawler")


@pytest.fixture
def ensure_media_crawler(media_crawler_path: Path) -> Path:
    """ç¡®ä¿ MediaCrawler å­˜åœ¨ï¼Œå¦åˆ™è·³è¿‡æµ‹è¯•"""
    if not media_crawler_path.exists():
        pytest.skip(f"MediaCrawler è·¯å¾„ä¸å­˜åœ¨: {media_crawler_path.absolute()}")

    main_py = media_crawler_path / "main.py"
    if not main_py.exists():
        pytest.skip(f"æ‰¾ä¸åˆ° main.py: {main_py}")

    return media_crawler_path


@pytest.fixture
def sample_detail_request() -> DetailRequest:
    """ç¤ºä¾‹è¯¦æƒ…è¯·æ±‚ï¼ˆæŠ–éŸ³ï¼‰"""
    return DetailRequest(
        platform=Platform.DY,
        login_type=LoginType.QRCODE,
        specified_ids="https://www.douyin.com/jingxuan?modal_id=7605333789232876826",
        get_comment=True,
        max_comments=10,
        headless=False,  # éæ— å¤´æ¨¡å¼ï¼Œè®©ç”¨æˆ·èƒ½çœ‹åˆ°äºŒç»´ç 
    )


@pytest.mark.real_crawler
@pytest.mark.human_interaction
@pytest.mark.timeout(TEST_TIMEOUT)
def test_douyin_detail_with_pydantic_model(
    ensure_media_crawler: Path,
    sample_detail_request: DetailRequest,
):
    """
    ä½¿ç”¨ Pydantic æ¨¡å‹æµ‹è¯•æŠ–éŸ³è¯¦æƒ…æ¨¡å¼

    æ­¤æµ‹è¯•éªŒè¯ï¼š
    1. DetailRequest æ¨¡å‹æ­£ç¡®æ„å»º
    2. CrawlerRunner æ­£ç¡®æ‰§è¡Œ
    3. CrawlerExecution è®°å½•å®Œæ•´çŠ¶æ€
    4. è¾“å‡ºæ–‡ä»¶è¢«æ­£ç¡®è¿½è¸ª
    """
    print("\n" + "=" * 60)
    print("ğŸ§ª E2E æµ‹è¯•ï¼šæŠ–éŸ³è¯¦æƒ…æ¨¡å¼")
    print("=" * 60)

    # 1. éªŒè¯è¯·æ±‚æ¨¡å‹
    print("\nğŸ“‹ è¯·æ±‚æ¨¡å‹:")
    print(f"  å¹³å°: {sample_detail_request.platform.value}")
    print(f"  ç±»å‹: {sample_detail_request.crawler_type.value}")
    print(f"  ID: {sample_detail_request.specified_ids}")
    print(f"  ç™»å½•: {sample_detail_request.login_type.value}")

    # 2. éªŒè¯ CLI å‚æ•°
    cli_args = sample_detail_request.to_cli_args()
    print(f"\nğŸ”§ CLI å‚æ•°: {' '.join(cli_args)}")

    # 3. åˆå§‹åŒ– Runner
    print(f"\nğŸš€ å¯åŠ¨ CrawlerRunner...")
    runner = CrawlerRunner(ensure_media_crawler)

    # 4. å¯åŠ¨çˆ¬è™«
    execution = runner.start(sample_detail_request)
    print(f"  è¿›ç¨‹ ID: {execution.process_id}")
    print(f"  çŠ¶æ€: {execution.status.value}")

    # 5. å®æ—¶è¾“å‡ºå¹¶ç­‰å¾…å®Œæˆ
    print("\nğŸ“Š å®æ—¶è¾“å‡º:")
    print("-" * 60)

    try:
        for line in runner.iter_output(execution, timeout=TEST_TIMEOUT):
            print(line)
    except TimeoutError:
        pytest.fail(f"æµ‹è¯•è¶…æ—¶ï¼ˆ{TEST_TIMEOUT}ç§’ï¼‰")

    print("-" * 60)

    # 6. éªŒè¯æ‰§è¡Œç»“æœ
    print("\nâœ… æ‰§è¡Œç»“æœ:")
    print(f"  æœ€ç»ˆçŠ¶æ€: {execution.status.value}")
    print(f"  è¿”å›ç : {execution.return_code}")
    print(f"  è€—æ—¶: {execution.duration_seconds:.1f} ç§’")
    print(f"  è¾“å‡ºè¡Œæ•°: {len(execution.stdout_lines)}")

    # 7. æ–­è¨€éªŒè¯
    assert execution.status == ExecutionStatus.COMPLETED, \
        f"æœŸæœ› COMPLETEDï¼Œå®é™…æ˜¯ {execution.status.value}"
    assert execution.return_code == 0, \
        f"æœŸæœ›è¿”å›ç  0ï¼Œå®é™…æ˜¯ {execution.return_code}"
    assert execution.process_id is not None
    assert execution.start_time is not None
    assert execution.end_time is not None

    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 60)


@pytest.mark.real_crawler
@pytest.mark.human_interaction
@pytest.mark.timeout(TEST_TIMEOUT)
def test_douyin_detail_with_output_verification(
    ensure_media_crawler: Path,
):
    """
    æµ‹è¯•å¹¶éªŒè¯è¾“å‡ºæ–‡ä»¶

    éªŒè¯ CrawlerExecution èƒ½æ­£ç¡®è¿½è¸ªè¾“å‡ºæ–‡ä»¶
    """
    print("\n" + "=" * 60)
    print("ğŸ§ª E2E æµ‹è¯•ï¼šè¾“å‡ºæ–‡ä»¶éªŒè¯")
    print("=" * 60)

    # æ„å»ºè¯·æ±‚
    request = DetailRequest(
        platform=Platform.DY,
        login_type=LoginType.QRCODE,
        specified_ids="https://www.douyin.com/jingxuan?modal_id=7605333789232876826",
        get_comment=True,
        max_comments=5,
        headless=False,
        save_option="json",
    )

    print(f"\nğŸ“‹ è¯·æ±‚: {request.platform.value} {request.crawler_type.value}")

    # æ‰§è¡Œ
    runner = CrawlerRunner(ensure_media_crawler)
    execution = runner.start(request)

    try:
        for _ in runner.iter_output(execution, timeout=TEST_TIMEOUT):
            pass
    except TimeoutError:
        pytest.fail("æµ‹è¯•è¶…æ—¶")

    # éªŒè¯æ‰§è¡ŒæˆåŠŸ
    assert execution.status == ExecutionStatus.COMPLETED

    # æŸ¥æ‰¾è¾“å‡ºæ–‡ä»¶
    print("\nğŸ“ æ‰«æè¾“å‡ºæ–‡ä»¶...")
    data_dir = ensure_media_crawler / "data"

    if data_dir.exists():
        json_files = list(data_dir.rglob("*.json"))
        print(f"  æ‰¾åˆ° {len(json_files)} ä¸ª JSON æ–‡ä»¶")

        if json_files:
            # éªŒè¯æ–‡ä»¶å­˜åœ¨ï¼ˆCrawlerExecution çš„æ ¡éªŒï¼‰
            try:
                execution.update_output_files(json_files[:5])  # æœ€å¤š5ä¸ª
                print(f"  âœ… å·²è¿½è¸ª {len(execution.output_files)} ä¸ªæ–‡ä»¶")
            except ValueError as e:
                print(f"  âš ï¸ æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")

            # éªŒè¯ JSON å†…å®¹
            for json_file in json_files[:2]:
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    print(f"  âœ… {json_file.name}: {len(data) if isinstance(data, list) else 'object'} æ¡è®°å½•")
                except Exception as e:
                    print(f"  âš ï¸ {json_file.name}: è¯»å–å¤±è´¥ - {e}")
    else:
        print(f"  âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")

    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)


@pytest.mark.real_crawler
@pytest.mark.human_interaction
@pytest.mark.timeout(TEST_TIMEOUT)
def test_model_to_execution_flow(ensure_media_crawler: Path):
    """
    æµ‹è¯•å®Œæ•´çš„æ•°æ®æµï¼šModel â†’ Runner â†’ Execution
    """
    print("\n" + "=" * 60)
    print("ğŸ§ª E2E æµ‹è¯•ï¼šå®Œæ•´æ•°æ®æµ")
    print("=" * 60)

    # 1. åˆ›å»ºæ¨¡å‹
    request = DetailRequest(
        platform=Platform.DY,
        specified_ids="https://www.douyin.com/jingxuan?modal_id=7605333789232876826",
        get_comment=True,
        max_comments=3,
        headless=False,
    )

    # 2. åºåˆ—åŒ–/ååºåˆ—åŒ–éªŒè¯
    request_data = request.model_dump()
    restored_request = DetailRequest.model_validate(request_data)
    assert restored_request.platform == request.platform
    print("âœ… æ¨¡å‹åºåˆ—åŒ–/ååºåˆ—åŒ–éªŒè¯é€šè¿‡")

    # 3. æ„å»ºå‘½ä»¤
    cmd = build_command(request)
    print(f"âœ… å‘½ä»¤æ„å»º: {' '.join(cmd[:5])}...")

    # 4. æ‰§è¡Œ
    runner = CrawlerRunner(ensure_media_crawler)
    execution = runner.start(request)

    # 5. éªŒè¯ Execution åˆå§‹çŠ¶æ€
    assert execution.request == request  # è¯·æ±‚å…³è”
    assert execution.status == ExecutionStatus.RUNNING
    print(f"âœ… Execution åˆ›å»º: pid={execution.process_id}")

    # 6. ç­‰å¾…å®Œæˆ
    for line in runner.iter_output(execution, timeout=TEST_TIMEOUT):
        pass

    # 7. éªŒè¯ Execution æœ€ç»ˆçŠ¶æ€
    assert execution.is_finished
    assert execution.duration_seconds is not None
    assert execution.duration_seconds > 0
    print(f"âœ… Execution å®Œæˆ: è€—æ—¶={execution.duration_seconds:.1f}s")

    # 8. Execution åºåˆ—åŒ–éªŒè¯
    execution_data = execution.model_dump()
    assert execution_data["status"] == "completed"
    assert execution_data["request"]["platform"] == "dy"
    print("âœ… Execution åºåˆ—åŒ–éªŒè¯é€šè¿‡")

    print("\n" + "=" * 60)
    print("âœ… å®Œæ•´æ•°æ®æµæµ‹è¯•é€šè¿‡ï¼")
    print("=" * 60)


@pytest.mark.real_crawler
@pytest.mark.human_interaction
@pytest.mark.timeout(TEST_TIMEOUT)
def test_execution_state_transitions(ensure_media_crawler: Path):
    """
    æµ‹è¯•æ‰§è¡ŒçŠ¶æ€è½¬æ¢

    éªŒè¯çŠ¶æ€æœºï¼šPENDING â†’ RUNNING â†’ COMPLETED
    """
    print("\n" + "=" * 60)
    print("ğŸ§ª E2E æµ‹è¯•ï¼šçŠ¶æ€è½¬æ¢")
    print("=" * 60)

    request = DetailRequest(
        platform=Platform.DY,
        specified_ids="https://www.douyin.com/jingxuan?modal_id=7605333789232876826",
        max_comments=3,
        headless=False,
    )

    # åˆå§‹çŠ¶æ€
    execution = CrawlerExecution(request=request)
    assert execution.status == ExecutionStatus.PENDING
    print(f"1. åˆå§‹çŠ¶æ€: {execution.status.value}")

    # å¯åŠ¨ â†’ RUNNING
    runner = CrawlerRunner(ensure_media_crawler)
    execution = runner.start(request)
    assert execution.status == ExecutionStatus.RUNNING
    assert execution.process_id is not None
    print(f"2. å¯åŠ¨å: {execution.status.value} (pid={execution.process_id})")

    # å®Œæˆ â†’ COMPLETED
    for _ in runner.iter_output(execution, timeout=TEST_TIMEOUT):
        pass

    assert execution.status in (ExecutionStatus.COMPLETED, ExecutionStatus.FAILED)
    print(f"3. ç»“æŸå: {execution.status.value}")

    if execution.status == ExecutionStatus.COMPLETED:
        print(f"   è¿”å›ç : {execution.return_code}")
        print(f"   è€—æ—¶: {execution.duration_seconds:.1f}s")

    print("\n" + "=" * 60)
    print("âœ… çŠ¶æ€è½¬æ¢æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
